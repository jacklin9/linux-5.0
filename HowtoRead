ABOUT KBUILD

1. Start with top level Makefile. 
    At line 17, set the first target(default target) to be _all.
    At line 559, set target _all to depends on all. 
    At line 595, initialize init-y, drivers-y, net-y, libs-y, core-y, virt-y. 
    At line 611, set target all to depend on vmlinux (this is to be overriden by arch specific Makefile)
    At line 628, include arch/$ARCH/Makefile at line 628. The arch specific Makefile does following.
        At the beginning, set some arch specific variables
        At line 234, initializes header-y, and update libs-y, core-y, drivers-?
        At line 266, set target all to depend on bzImage, bzImage depend on vmlinux, and the command to
            generate bzImage based on vmlinux (see arch/x86/Makefile:271 for details).  Here one import 
            command is:
            $(Q)$(MAKE) $(build)=$(boot) $(KBUILD_IMAGE)
            This command run make -f scripts/Makefile.build obj=arch/x86/boot bzImage
    At line 1027, set vmlinux to depend on scripts/link-vmlinux.sh, $(vmlinux-deps), etc. The command is link-vmlinux.
    At line 1043, set targets in $(vmlinux-deps) to depend on $(vmlinux-dirs)
    At line 1052, set targets in $(vmlinux-dirs) to depend on prepare. Here the command run for each dir in $(vmlinux-dirs) is:
        $(Q)$(MAKE) $(build)=$@ need-builtin=1
        This command run make -f scripts/Makefile.build obj=dir need-builtin=1. The Makefile.build does some
        common init and include the Makefile in the dir (say init) and 


2. So from above we can see the workhorse is scripts/Makefile.build. Briefly speaking, this Makefile runs
    Makefiles in sub dirs and then compile files in obj dir. In detail:
    At line 9, set the first target(default target) to be __build
    At line 45, include obj/Kbuild or obj/Makefile if obj/Kbuild doesn't exist. Generally the Kbuild/Makefile
        set some variables to be used by this general Makefile
    At line 73, set target __build to depend on $(builtin-target) $(lib-target) $(extra-y)) $(subdir-ym) $(always)
    At line 397, set target $(subdir-obj-y) to depend on $(subdir-ym)
    At line 494, set the command of each target in $(subdir-ym) as:
        $(Q)$(MAKE) $(build)=$@ need-builtin=$(if $(findstring $@,$(subdir-obj-y)),1)
        So that each Makefile in subdir of obj will be run

3. File arch/x86/boot/Makefile is included by scripts/Makefile.build when running command at arch/x86/Makefile:271
    At line 80, set target bzImage to depend on setup.bin, vmlinux.bin
    At line 85, set target vmlinux.bin to depend on arch/x86/compressed/vmlinux
    At line 108, set target setup.bin to depend on setup.elf (built from files in arch/x86/boot/{header.S,....})
    At line 111, set arch/x86/compressed/vmlinux to be generated with command:
        $(Q)$(MAKE) $(build)=$(obj)/compressed $@
        In file arch/x86/compressed/Makefile
        At line 115, set target vmlinux to depend on arch/x86/compressed/{vmlinux.lds,head_64.,misc.o,piggy.o, etc} 
        At line 157, set target piggy.S to depend on vmlinux.bin
        At line 119, set vmlinux.bin to depend on *file* vmlinux
4. The structure of the kernel image is as follows:
    +------------------------------+--------------------------------------------+------------------------------------------------+
    |           setup              |                    head                    |                   piggy (Compressed)           |
    |(arch/x86/boot/header.S, etc) |(arch/x86/boot/compressed/head_64.S, etc)   |  vmlinux(arch/x86/kernel/head_64.S, etc)       |
    |       Real mode code         |                                     Protected code (loaded at 1M)                           |
    +------------------------------+--------------------------------------------+------------------------------------------------+
    See https://developer.ibm.com/articles/l-linuxboot/ for boot process.
    See document Documentation/x86/boot.txt for boot protocol

	Real mode code can be loaded anywhere under 1M (the lower the better to avoid BIOS data) because it can be relocated by setting CS, DS correctly. Generally real mode code does 2 things:
	a. copy boot parameters
	b. setup GDT, switch to protected mode and jump to protected code
	Note that a boot loader may ignore the real mode code and load protected code directly.

	Protected code is also relocatable and thus can be loaded anywhere above 1M. It does following things:
	a. Enable 4 level paging long mode
	b. Enable 5 level paging long mode with the help of trampoline
	c. Does relocation
	d. Move itself to a safe place and decompress the vmlinux image
	e. Relocate the decompressed vmlinux image and jump to it
	Note that the protected code consists of two parts: 1. the 32 bit code without paging; 2. 64 bit code. A boot loader may ignore the 32 bit part and jump to 64 bit directly.
5. So start reading kernel code from file arch/x86/boot/header.S. This should be read together with setup.ld
6. arch/x86/boot/header.S contains two parts:
    Code from line 51 to line 287 is the boot sector. This sector contains two information:
    1. If it is built for EFI, it contains PE header so that EFI boot can load the kernel
    2. If it is not built for EFI, it contains a small stub to print error message if it is loaded by a non-compatible loader
    This part also contains some fields filled by build.c. These fields will be used by the second part.

    Code from line 289 is the real entry point of the startup code. This file does some real mode init and
    go to arch/x86/boot/compressed/head_64.S
7. arch/x86/boot/compressed/head_64.S. This file should be read together with arch/x86/boot/compressed/vmlinux.lds.S.
    Now %esi contains the boot_params. Start running at arch/x86/boot/compressed/head_64.S:48. It does some
    64bit paging initialization, move itself to a configured place and decompress the piggy part and jump to
    it (arch/x86/kernel/head_64.S:55)
    The compressed kernel image (ZO), has been moved so that its position
    is against the end of the buffer used to hold the uncompressed kernel
    image (VO) and the execution environment (.bss, .brk), which makes sure
    there is room to do the in-place decompression. (See header.S for the
    calculations.)
    
                                |-----compressed kernel image------|
                                V                                  V
    0                       extract_offset                      +INIT_SIZE
    |-----------|---------------|-------------------------|--------|
                |               |                         |        |
               VO__text      startup_32 of ZO          VO__end    ZO__end
                 ^                                         ^
                 |-------uncompressed kernel image---------|

8. The real kernel is generated by linking the following.
    init-y		:= init/
    drivers-y	:= drivers/ sound/ firmware/
    net-y		:= net/
    libs-y		:= lib/
    core-y		:= usr/
    virt-y		:= virt/
    -------------------------------------------
    head-y := arch/x86/kernel/head_$(BITS).o
    head-y += arch/x86/kernel/head$(BITS).o
    head-y += arch/x86/kernel/ebda.o
    head-y += arch/x86/kernel/platform-quirks.o

    libs-y  += arch/x86/lib/

    core-y += arch/x86/

    ===========================================
    vmlinux-deps := arch/$(SRCARCH)/kernel/vmlinux.lds      $(head-y) $(init-y)      $(core-y) $(libs-y2) $(drivers-y) $(net-y) $(virt-y))      $(libs-y1)
9. The real kernel starts running at arch/x86/kernel/head_64.S:55. This should be read together with file 
    arch/x86/kernel/vmlinux.lds.S. This file calls arch/x86/kernel/head64.c, which in turn calls start_kernel 
    at init/main.c:537.

10. Trap handler is initialized in function trap_init:
	1. call function idt_setup_traps to fill the IDT table with a table in arch/x86/kernel/idt.c:74. Symbols here are defined in file arch/x86/entry/entry_64.S starting from line 970
	2. call function cpu_init, which in turn calls function syscall_init. This function fills the addr of syscall entry(entry_SYSCALL_64) into MSR register MSR_LSTAR. entry_SYSCALL_64 eventually calls functions in table sys_call_table whose content is defined in file arch/x86/entry/syscalls/syscall_64.tbl
11. Interrupt handler is initialzed in function init_IRQ. The function calls x86_init.irqs.intr_init, which is actually native_init_IRQ. This function calls idt_setup_apic_and_irq_gates. This function fill idt_table with table apic_idts and table irq_entries_start

12. When kernel init is almost done, kernel create a kernel thread running kernel_init, and another kernel thread running kthreadd, and jump to do_idle

Initialization Process Explained
1. KERNEL STACK: at arch/x86/kernel/head_64.S:77, set stack to be the end of init task kernel stack
2. PAGE MAPPING: in function __startup_64, use early_top_pgt to set up kernel virtual addr space mapping and identical mapping of physical mem used by kernel. In kernel virtual addr mapping, pages used by all other levels are statically allocated; in identical mapping, allocate pages in early_dynamic_pgts pool which is in section .init.data
3. KERNEL STACK: at arch/x86/kernel/head_64.S:171, set stack to be the end of init task kernel stack again
4. PAGE MAPPING: set gdt by using early_gdt_descr which points to per-cpu gdt
5. PAGE MAPPING: in function x86_64_start_kernel, call reset_early_page_tables to clear the identical mapping and reset early_dynamic_pgts pool
6. PAGE MAPPING: in function x86_64_start_kernel, call clear_page to clear init_top_pgt
7. KASAN & PAGE MAPPING: in function x86_64_start_kernel, call kasan_early_init to add statically allocated page kasan_early_shadow_page to both early_top_pgt and init_top_gdt
8. IDT: in function x86_64_start_kernel, call idt_setup_early_handler to fill idt_table with early_idt_handler_array which processes page fault exception seariously and ignores other exceptions (calls early_fixup_exception)
9. PAGE MAPPING: at x86_64_start_kernel:465, fill init_top_gdt with kernel virtual addr mapping
10. KERNEL STACK: in start_kernel, call set_task_stack_end_magic to fill the end of init task kernel stack with stack protector value 
11. DEBUG: in start_kernel, call debug_objects_early_init to init obj_hash which is a hashlist of debug_obj, and init linked list obj_pool by adding debug_obj in obj_static_pool
12. CGROUP: in start_kernel, call cgroup_init_early to init cgrp_dfl_root(cgroup tree root) and cgroup_subsys(subsys list)
13. IDT: at start_kernel:548, disable IRQ
14. SMP: in startup_kernel, call boot_cpu_init to mark boot CPU online, active, present, possible
15. MEM MANAGE: in setup_arch, call memblock_reserve to add mem region occupied by kernel to memblock.reserved
16. MEM MANAGE: in setup_arch, call memblock_reserve to add first page to memblock.reserved
16. MEM MANAGE: in setup_arch, call early_reserve_initrd to add initrd to memblock.reserved
17. IDT: in setup_arch, call idt_setup_early_traps to fill idt_table with entries in table early_idts. This table contains 2 entries, one(entry debug) for handling debug exception, the other(entry int3) for handling breakpoint exception
18. PAGE MAPPING: in setup_arch, call early_ioremap_init:
	1. Call early_ioremap_setup to to init slot_virt array which stores starting virtual address of each fix slot (8 slots, each slot have 64 pages)
	2. Clean up statically allocated page bm_pte and install the page bm_pte to an pmd entry according to the starting virtual addr of fixmap
19. MEM MANAGE: in setup_arch, call e820__memory_setup to copy e820 table to e820_table and resolve overlap and type conflicts. The function also copies e820_table to e820_table_kexec and e820_table_firmware
20. MEM MANAGE: in setup_arch, init init_mm from line 925 to 930
21. CONFIG: in setup_arch, call parse_early_param to init all variables with early = true registered by macro early_param
22. MEM MANAGE: in setup_arch, call memblock_x86_reserve_range_setup_data to add ranges used by setup_data in boot params to memblock.reserved
23. MEM MANAGE: in setup_arch, call e820__reserve_setup_data to add ranges used by setup_data in boot params to e820_table, e820_table_kexec
24. TIME: in setup_arch, call tsc_early_init to initialize cpu_khz and tsc_khz, loops_per_jiffy 
25. MEM MANAGE: in setup_arch, call e820_add_kernel_range to make sure physical mem used by kernel is covered by e820_table and marked as ram. If not, remove the kernel range from e820_table and add it to the table again. Then setup_arch calls trim_bios_range to make sure first page is reserved in e820_table, [640k, 1M] is not in e820_table. trim_bios_range also call e820__update_table to sanitize the table
26. MEM MANAGE: in setup_arch, call early_gart_iommu_check to detect graphical card mem and add it to e820_table as reserved mem and then sanitize the e820_table
27. SMP & MEM MANAGE: in setup_arch, call find_smp_config to find the addr of smp config table, store the addr to mpf_base, and reserve mem of the table (add the region to memblock.reserved)
28. PAGE MAPPING & MEM MANAGE: in setup_arch, call early_alloc_pgt_buf to enlarge brk section and init pgt_buf_start, pgt_buf_end to the start of brk, and pgt_buf_top to end of the enlarged brk. then call reserve_brk to put the enlarged brk region to memblock.reserved
29. MEM MANAGE: in setup_arch, call memblock_set_current_limit to set memblock.current_limit to 1M
30. MEM MANAGE: in setup_arch, call e820__memblock_setup to allow changing memblock.memory and memblock.reserved size, and add ram regions and kernel mem region in e820_table to memblock.memory. Then call reserve_bios_regions to add bios mem to memblock.reserved
31. MEM MANAGE: in setup_arch, call reserve_real_mode to figure out the size of real mode blob and allocate mem under 1M, put the region to memblock.reserved, and set real_mode_header to the beginning of the region. Then call trim_platform_memory_ranges and trim_low_memory_range to add some special mem ranges to memblock.reserved
32. PAGE MAPPING: in setup_arch, call init_mem_mapping to set pti_mode and cpu capability(like PSE, PEG, in function pti_check_boottime_disable), set page_size_mask(in function probe_page_size_mask), set PCID(in function setup_pcid), map phy addr [0, 1M) to [PAGE_OFFSET, PAGE_OFFSET + 1M) in init_mm.pgd that is swapper_pg_dir which is defined as init_top_pgt(in function init_memory_mapping), set trampoline_pgd_entry(in function init_trampoline), map phy addr [1M, kernel_end) and [kenrel_end, mem end)(by calling function memory_map_bottom_up). During these mappings, required page mem is allocated in brk section if brk can be used, otherwise memblock is used, and variable nr_pfn_mapped and pfn_mapped are updated according to the mapped ranges
33. IDT: in setup_arch, call idt_setup_early_pf to set X86_TRAP_PF entry in idt_table to be function page_fault(arch/x86/entry/entry_64.S:1143)
34. PRINT: in setup_arch, call setup_log_buf to dynamically allocate log_buf in memblock, update log_buf_len, and copy old buf content to the new one
35. FS & MEM MANAGE: in setup_arch, call reserve_initrd to make sure mem used by initrd is mapped and set initrd_start and initrd_end 
36. ACPI: in setup_arch, call acpi_table_upgrade to find all ACPI tables in initrd, store them in acpi_initrd_files, allocate mem for ACPI table in memblock and store addr in acpi_tables_addr, and copy ACPI tables to acpi_tables_addr
37. SMP: in setup_arch, call vsmp_init to check if the box support ScaleMP vSMP (set is_vsmp), and if vSMP is supported, set x86_platform.apic_post_init to vsmp_apic_post_init, set setup_max_cpus(by calling vsmp_cap_cpus)
38. ACPI & SMP & DMI: in setup_arch, call acpi_boot_table_init to config DMI hardware according to acpi_dmi_table, init acpi_gbl_root_table_list.tables, acpi_gbl_root_table_list.max_table_count, acpi_gbl_root_table_list.flags, get addr of RSDP, parse it and get addr of RSDT(for ACPI version 1) or XSDT(for ACPI version > 1), and finally get tables in the RSDT/XSDT and store it to acpi_gbl_root_table_list.tables. If table is FADT, store the index of the table entry in acpi_gbl_root_table_list.tables to acpi_gbl_fadt_index 
39. ACPI & IDT: in setup_arch, call early_acpi_boot_init to parse MADT(Multiple APIC Description Table, by calling early_acpi_process_madt) and store local APIC addr to acpi_lapic_addr 
40. MEM MANAGE: in setup_arch, call initmem_init to set the NUMA node id of each region in memblock.memory
41. SYSCALL: in setup_arch, call map_vsyscall to map __vsyscall_page page to fixmap slot VSYSCALL_PAGE and set it accessible from user mode
42. IDT: in setup_arch, call generic_apic_probe to determin the APIC driver in a list which is defined by macro apic_driver and store the result to variable apic
43. ACPI & IDT: in setup_arch, call acpi_boot_init to parse table ACPI_SIG_BOOT(save CMOS port to sbf_port), ACPI_SIG_FADT(store timer port to pmtmr_ioport), Multiple APIC Description Table(MADT, store lapic addr to acpi_lapic_addr),ACPI_SIG_HPET(store HPET base addr to hpet_address and blockid to hpet_blockid)  
44. ACPI & SMP: in setup_arch, call sfi_init to disable SFI(by setting sfi_disabled) if ACPI is enabled. If SFI is enabled, search SFI table and assign the phy addr to syst_pa, parse the table, and init LAPIC by setting mp_lapic_addr, parse CPU tables(by setting cpu_num and lapic ids) & IOAPIC tables
45. SMP: in setup_arch, call get_smp_config to parse SMP config table stored in mpf_base and set mp_lapic_addr 
46. NUMA & SMP: in setup_arch, call init_cpu_to_node to set each CPU's node and the result is stored in x86_cpu_to_node_map
47. ACPI & RESOURCE: in setup_arch, call io_apic_init_mappings to allocate resource array ioapic_res for IOAPIC's, map the IOAPIC's base addr to fix map slots, and store phy addrs to resource array ioapic_res
48. MEM MANAGE & RESOURCE: in setup_arch, call e820__reserve_resources to allocate mem of resource struct array for entries in e820_table, store the result to e820_res, init each resource entry in the array according to the start and end value of each entry in e820_table
49. MEM MANAGE: in setup_arch, call e820__register_nosave_regions to generat a region struct for each gap between e820_table entries and non usual mem, and put the region to list nosave_regions. These no save regions will not be saved during hibernation
50. RESOURCE: in setup_arch, call x86_init.resources.reserve_resources to request resources listed in standard_io_resources from ioport_resource 
51. PCI: in setup_arch, call e820__setup_pci_gap to find a gap of size 4M below 4G range in e820_table. If not found, take the addr of 1M beyond last phy mem as the gap start point in 64 bit mode, and take addr 256M as the gap start point in 32 bit mode. Then assign the addr to pci_mem_start 
52. APIC: in setup_arch, call mcheck_init to init machine check. In detail, store thermal LVT to lvtthmr_init, add notifier block first_nb, mce_srao_nb, and mce_default_nb to x86_mce_decoder_chain, add mce_gen_pool_process to work queue mce_work, add mce_irq_work_cb to irq work mce_irq_work
53. TIME: in setup_arch, call register_refined_jiffies to init clock source refined_jiffies based on clocksource_jiffies and register the clock source
54. RANDOM: in start_kernel, call add_latent_entropy to add latent_entropy to entropy pool, then call add_device_randomness to add command_line to entropy pool
55. KERNEL STACK: in start_kernel, call boot_init_stack_canary to calulate stack canary by mixing the random value from entropy pool and tsc value (in-cpu timestamp counter), and assign this value to init_task.stack_canary and irq_stack_union.stack_canary 
56. SMP & MEM MANAGE: in start_kernel, call mm_init_cpumask to clear cpu_bitmap of mm_struct init_mm
57. CONFIG & COMMAND LINE: in start_kernel, call setup_command_line to alloc mem from memblock for saved_command_line and static_command_line, copy boot_command_line(initialized in copy_bootdata called by x86_64_start_kernel) to saved_command_line, and copy command_line to static_command_line
58. PER CPU: in start_kernel, call setup_per_cpu_areas to do the following:
	1. Calculate the allocation info of per cpu mem (cpu group, allocation size, unit size-mem needed by one cpu)
	2. Allocate mem for each cpu group and copy static per cpu data to each cpu's unit
	3. Store group number to pcpu_nr_groups, store each group's offset to map pcpu_group_offsets, store each group's mem size to pcpu_group_sizes, store each cpu's unit id to map pcpu_unit_map, store each cpu's mem offset to map pcpu_unit_offsets, store each unit's size in page to pcpu_unit_pages, store each unit's size in byte to pcpu_unit_size, allocate the first chunk for dynamic per-cpu and store the addr to pcpu_first_chunk, and store the base addr of mem to pcpu_base_addr   
	4. For each cpu, set per_cpu_offset to be the sum of offset between the cpu's unit and the base addr of allocated mem, and the delta between base addr of allocated mem and start virtual addr of per-cpu area
59. SMP: in start_kernel, call smp_prepare_boot_cpu to get the current cpu id, load GDT of the current CPU, set gs base to the kernel irq stack, and set the current cpu online
60. MEM MANAGE: in start_kernel, call build_all_zonelists to find each node's fallback nodes, add zone list of each fallback node to this node's fallback zone list, and add this node's zone list to this node's nofallback zone list
61. TEST: in start_kernel, call setup_log_buf to update new_log_buf_len according to cpu num if necessary, allocate new log buf, and copy the content in old buf to the new one
62. FS: in start_kernel, call vfs_caches_init_early to init hash table in_lookup_hashtable (an array of list) as empty, init dentry_hashtable(if not numa configured; otherwise, don't initialize the hashtable here because hashtable will distribute across nodes), and init inode_hashtable(if not numa configured; otherwise, don't initialize the hashtable here because hashtable will distribute across nodes)
63. IDT: in start_kernel, call trap_init to:
	1. Set up per cpu entry area in fixmap and map per cpu vars  to cpu entry area fields gdt, entry_stack_page, tss, exception_stacks so that in future these vars can be accessed through cpu entry area
	2. Initialize idt_table from def_idts
	3. Map idt_table to fixed addr CPU_ENTRY_AREA_RO_IDT to avoid kernel addr exposure
	4. Init the current CPU (boot or master cpu): write cr4 of this cpu to per cpu var cpu_tlbstate.cr4, set this cpu's numa node, load gdt again, load idt again, set init_task.thread.tls_array to be empty, set syscall instruction handler to be entry_SYSCALL_64, let orig_ist ist entries and tss ist entries point to regions in cpu entry area field exception_stacks
	5. Initialze idt_table from ist_idts
	6. Copy idt_table to debug_idt_table and update it with dbg_idts
64. MEM MANAGE: in start_kernel, call mm_init to: (support 3 mem models: flatmem, discontigmem, sparsemem, see https://www.kernel.org/doc/html/latest/vm/memory-model.html)
	1. detect iommu in dep topology order:
	pci_xen_swiotlb_detect
	|
	pci_swiotlb_detect_override
	|
	pci_swiotlb_detect_4gb
	|________________________________________________________________________
	|							  |											|
	gart_iommu_hole_init	detect_calgary							detect_intel_iommu
	|
	amd_iommu_detect
	2. Init each page's page struct according to memblock.memory and memblock.reserved, and put available pages to buddy system (by calling mem_init)
	3. Init slab (or slob, or slub) by calling kmem_cache_init
	4. Init page table lock kmem_cache and store it to page_ptl_cachep by calling pgtable_init
	5. For each cpu, init its vmap_block_queue and vfree_deferred by setting work queue to function free_work. According to the vm_struct list vmlist, allocate a vmap_area for each item in the list and put the vmap_area to vmap_area_root rb tree
=================================================================================
65. PROC: in start_kernel, call sched_init
